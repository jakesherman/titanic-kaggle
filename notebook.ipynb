{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fancyimpute\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is going to be to combine the training and test sets so that any data transformations / feature engineering is easily applied to both. Only the training set is labeled, so I will create values of -999 for `Survived` in the test subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat(\n",
    "    [train.assign(Train = 1), \n",
    "    test.assign(Train = 0).assign(Survived = -999)[list(train) + ['Train']]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with `Name` - create last name, title, family features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_lastname = lambda x: x.split(',')[0]\n",
    "\n",
    "def extract_title(x):\n",
    "    title = x.split(',')[1].split('.')[0][1:]\n",
    "    if title in ['Mlle', 'Ms']:\n",
    "        title = 'Miss'\n",
    "    elif title == 'Mme':\n",
    "        title = 'Mrs'\n",
    "    elif title in ['Rev', 'Dr', 'Major', 'Col', 'Capt', 'Jonkheer', 'Dona']:\n",
    "        title = 'Esteemed'\n",
    "    elif title in ['Don', 'Lady', 'Sir', 'the Countess']:\n",
    "        title = 'Royalty'\n",
    "    return title\n",
    "    \n",
    "data = (data\n",
    "    .assign(LastName = lambda x: x.Name.map(extract_lastname))\n",
    "    .assign(Title = lambda x: x.Name.map(extract_title))\n",
    "    .assign(FamSize = lambda x: x.SibSp + x.Parch + 1)\n",
    "    .assign(Family = lambda x: [a + '_' + str(b) for a, b in \n",
    "                                zip(list(x.LastName), list(x.FamSize))])\n",
    "    .drop(['Name', 'SibSp', 'Parch', 'LastName'], axis = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with `Ticket` - to reduce overfitting, create dummy variables for tickets that are shared among two or more passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ticket_counts(data):\n",
    "    ticket_to_count = dict(data.Ticket.value_counts())\n",
    "    data['TicketCount'] = data['Ticket'].map(ticket_to_count.get)\n",
    "    data['Ticket'] = np.where(data['TicketCount'] > 1, data['Ticket'], np.nan)\n",
    "    return data.drop(['TicketCount'], axis = 1)\n",
    "\n",
    "data = data.pipe(ticket_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with the `Cabin` feature - creating a deck feature (the letter in the cabin name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_letter = np.vectorize(lambda x: x[:1]) \n",
    "\n",
    "data = (data\n",
    "        .assign(Deck = lambda x: np.where(\n",
    "            pd.notnull(x.Cabin), first_letter(x.Cabin.fillna('z')), x.Cabin))\n",
    "        .assign(Deck = lambda x: np.where(x.Deck == 'T', np.nan, x.Deck))\n",
    "        .drop(['Cabin'], axis = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns we don't need, convert Sex to a binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = (data\n",
    "        .drop(['PassengerId'], axis = 1)\n",
    "        .assign(Sex = lambda x: np.where(x.Sex == 'male', 1, 0))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy variables for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dummy_nans(data, col_name):\n",
    "    deck_cols = [col for col in list(data) if col_name in col]\n",
    "    for deck_col in deck_cols:\n",
    "        data[deck_col] = np.where(\n",
    "            data[col_name + 'nan'] == 1.0, np.nan, data[deck_col])\n",
    "    return data.drop([col_name + 'nan'], axis = 1)\n",
    "\n",
    "data = (data\n",
    "        .assign(Pclass = lambda x: x.Pclass.astype(str))\n",
    "        .pipe(pd.get_dummies, columns = ['Pclass', 'Family', 'Title', 'Ticket'])\n",
    "        .pipe(pd.get_dummies, columns = ['Deck'], dummy_na = True)\n",
    "        .pipe(pd.get_dummies, columns = ['Embarked'], dummy_na = True)\n",
    "        .pipe(create_dummy_nans, 'Deck_')\n",
    "        .pipe(create_dummy_nans, 'Embarked_')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MICE] Completing matrix with shape (1309, 1167)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.032\n",
      "[MICE] Starting imputation round 2/110, elapsed time 4.083\n",
      "[MICE] Starting imputation round 3/110, elapsed time 7.139\n",
      "[MICE] Starting imputation round 4/110, elapsed time 11.534\n",
      "[MICE] Starting imputation round 5/110, elapsed time 14.098\n",
      "[MICE] Starting imputation round 6/110, elapsed time 16.017\n",
      "[MICE] Starting imputation round 7/110, elapsed time 17.391\n",
      "[MICE] Starting imputation round 8/110, elapsed time 18.623\n",
      "[MICE] Starting imputation round 9/110, elapsed time 20.098\n",
      "[MICE] Starting imputation round 10/110, elapsed time 24.462\n",
      "[MICE] Starting imputation round 11/110, elapsed time 26.723\n",
      "[MICE] Starting imputation round 12/110, elapsed time 30.069\n",
      "[MICE] Starting imputation round 13/110, elapsed time 33.560\n",
      "[MICE] Starting imputation round 14/110, elapsed time 36.693\n",
      "[MICE] Starting imputation round 15/110, elapsed time 38.240\n",
      "[MICE] Starting imputation round 16/110, elapsed time 39.604\n",
      "[MICE] Starting imputation round 17/110, elapsed time 40.805\n",
      "[MICE] Starting imputation round 18/110, elapsed time 42.278\n",
      "[MICE] Starting imputation round 19/110, elapsed time 43.481\n",
      "[MICE] Starting imputation round 20/110, elapsed time 44.870\n",
      "[MICE] Starting imputation round 21/110, elapsed time 46.315\n",
      "[MICE] Starting imputation round 22/110, elapsed time 47.519\n",
      "[MICE] Starting imputation round 23/110, elapsed time 48.939\n",
      "[MICE] Starting imputation round 24/110, elapsed time 50.143\n",
      "[MICE] Starting imputation round 25/110, elapsed time 51.521\n",
      "[MICE] Starting imputation round 26/110, elapsed time 52.868\n",
      "[MICE] Starting imputation round 27/110, elapsed time 54.065\n",
      "[MICE] Starting imputation round 28/110, elapsed time 56.214\n",
      "[MICE] Starting imputation round 29/110, elapsed time 59.066\n",
      "[MICE] Starting imputation round 30/110, elapsed time 61.485\n",
      "[MICE] Starting imputation round 31/110, elapsed time 64.215\n",
      "[MICE] Starting imputation round 32/110, elapsed time 66.567\n",
      "[MICE] Starting imputation round 33/110, elapsed time 68.849\n",
      "[MICE] Starting imputation round 34/110, elapsed time 70.428\n",
      "[MICE] Starting imputation round 35/110, elapsed time 71.628\n",
      "[MICE] Starting imputation round 36/110, elapsed time 73.093\n",
      "[MICE] Starting imputation round 37/110, elapsed time 74.302\n",
      "[MICE] Starting imputation round 38/110, elapsed time 75.835\n",
      "[MICE] Starting imputation round 39/110, elapsed time 78.436\n",
      "[MICE] Starting imputation round 40/110, elapsed time 80.344\n",
      "[MICE] Starting imputation round 41/110, elapsed time 82.624\n",
      "[MICE] Starting imputation round 42/110, elapsed time 85.351\n",
      "[MICE] Starting imputation round 43/110, elapsed time 87.932\n",
      "[MICE] Starting imputation round 44/110, elapsed time 90.243\n",
      "[MICE] Starting imputation round 45/110, elapsed time 92.598\n",
      "[MICE] Starting imputation round 46/110, elapsed time 94.952\n",
      "[MICE] Starting imputation round 47/110, elapsed time 97.273\n",
      "[MICE] Starting imputation round 48/110, elapsed time 99.569\n",
      "[MICE] Starting imputation round 49/110, elapsed time 101.882\n",
      "[MICE] Starting imputation round 50/110, elapsed time 103.744\n",
      "[MICE] Starting imputation round 51/110, elapsed time 104.949\n",
      "[MICE] Starting imputation round 52/110, elapsed time 106.397\n",
      "[MICE] Starting imputation round 53/110, elapsed time 107.858\n",
      "[MICE] Starting imputation round 54/110, elapsed time 109.060\n",
      "[MICE] Starting imputation round 55/110, elapsed time 110.409\n",
      "[MICE] Starting imputation round 56/110, elapsed time 111.612\n",
      "[MICE] Starting imputation round 57/110, elapsed time 112.926\n",
      "[MICE] Starting imputation round 58/110, elapsed time 114.391\n",
      "[MICE] Starting imputation round 59/110, elapsed time 115.604\n",
      "[MICE] Starting imputation round 60/110, elapsed time 116.981\n",
      "[MICE] Starting imputation round 61/110, elapsed time 118.183\n",
      "[MICE] Starting imputation round 62/110, elapsed time 119.597\n",
      "[MICE] Starting imputation round 63/110, elapsed time 121.068\n",
      "[MICE] Starting imputation round 64/110, elapsed time 122.277\n",
      "[MICE] Starting imputation round 65/110, elapsed time 123.750\n",
      "[MICE] Starting imputation round 66/110, elapsed time 124.954\n",
      "[MICE] Starting imputation round 67/110, elapsed time 126.389\n",
      "[MICE] Starting imputation round 68/110, elapsed time 127.769\n",
      "[MICE] Starting imputation round 69/110, elapsed time 128.974\n",
      "[MICE] Starting imputation round 70/110, elapsed time 130.433\n",
      "[MICE] Starting imputation round 71/110, elapsed time 131.636\n",
      "[MICE] Starting imputation round 72/110, elapsed time 133.027\n",
      "[MICE] Starting imputation round 73/110, elapsed time 134.472\n",
      "[MICE] Starting imputation round 74/110, elapsed time 135.678\n",
      "[MICE] Starting imputation round 75/110, elapsed time 137.135\n",
      "[MICE] Starting imputation round 76/110, elapsed time 138.456\n",
      "[MICE] Starting imputation round 77/110, elapsed time 139.662\n",
      "[MICE] Starting imputation round 78/110, elapsed time 141.113\n",
      "[MICE] Starting imputation round 79/110, elapsed time 142.323\n",
      "[MICE] Starting imputation round 80/110, elapsed time 143.717\n",
      "[MICE] Starting imputation round 81/110, elapsed time 145.078\n",
      "[MICE] Starting imputation round 82/110, elapsed time 146.321\n",
      "[MICE] Starting imputation round 83/110, elapsed time 147.701\n",
      "[MICE] Starting imputation round 84/110, elapsed time 148.908\n",
      "[MICE] Starting imputation round 85/110, elapsed time 150.268\n",
      "[MICE] Starting imputation round 86/110, elapsed time 151.660\n",
      "[MICE] Starting imputation round 87/110, elapsed time 152.987\n",
      "[MICE] Starting imputation round 88/110, elapsed time 154.654\n",
      "[MICE] Starting imputation round 89/110, elapsed time 157.091\n",
      "[MICE] Starting imputation round 90/110, elapsed time 159.300\n",
      "[MICE] Starting imputation round 91/110, elapsed time 160.700\n",
      "[MICE] Starting imputation round 92/110, elapsed time 161.909\n",
      "[MICE] Starting imputation round 93/110, elapsed time 163.328\n",
      "[MICE] Starting imputation round 94/110, elapsed time 164.532\n",
      "[MICE] Starting imputation round 95/110, elapsed time 165.896\n",
      "[MICE] Starting imputation round 96/110, elapsed time 167.379\n",
      "[MICE] Starting imputation round 97/110, elapsed time 170.100\n",
      "[MICE] Starting imputation round 98/110, elapsed time 174.869\n",
      "[MICE] Starting imputation round 99/110, elapsed time 178.878\n",
      "[MICE] Starting imputation round 100/110, elapsed time 184.748\n",
      "[MICE] Starting imputation round 101/110, elapsed time 188.748\n",
      "[MICE] Starting imputation round 102/110, elapsed time 193.007\n",
      "[MICE] Starting imputation round 103/110, elapsed time 197.058\n",
      "[MICE] Starting imputation round 104/110, elapsed time 200.964\n",
      "[MICE] Starting imputation round 105/110, elapsed time 202.332\n",
      "[MICE] Starting imputation round 106/110, elapsed time 205.251\n",
      "[MICE] Starting imputation round 107/110, elapsed time 208.310\n",
      "[MICE] Starting imputation round 108/110, elapsed time 211.920\n",
      "[MICE] Starting imputation round 109/110, elapsed time 213.880\n",
      "[MICE] Starting imputation round 110/110, elapsed time 215.092\n",
      "Number of NAs: 0\n"
     ]
    }
   ],
   "source": [
    "def impute(data):\n",
    "    impute_missing = data.drop(['Survived', 'Train'], axis = 1)\n",
    "    impute_missing_cols = list(impute_missing)\n",
    "    filled_soft = fancyimpute.MICE().complete(np.array(impute_missing))\n",
    "    results = pd.DataFrame(filled_soft, columns = impute_missing_cols)\n",
    "    results['Train'] = list(data['Train'])\n",
    "    results['Survived'] = list(data['Survived'])\n",
    "    assert results.isnull().sum().sum() == 0, 'Not all NAs removed'\n",
    "    return results\n",
    "\n",
    "data = data.pipe(impute)\n",
    "print 'Number of NAs:', data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into separate training and predicting sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcomes = np.array(data.query('Train == 1')['Survived'])\n",
    "train = (data.query('Train == 1')\n",
    "         .drop(['Train', 'Survived'], axis = 1))\n",
    "to_predict = (data.query('Train == 0')\n",
    "              .drop(['Train', 'Survived'], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, randomly split the training set into training and test sets using hold-out cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train, outcomes, test_size = 0.2, random_state = 50)\n",
    "\n",
    "\n",
    "def train_test_model(model, hyperparameters, X_train, X_test, y_train, y_test,\n",
    "                    folds = 5):\n",
    "    \"\"\"\n",
    "    Given a [model] and a set of possible [hyperparameters], along with \n",
    "    matricies corresponding to hold-out cross-validation, returns a model w/ \n",
    "    optimized hyperparameters, and prints out model evaluation metrics.\n",
    "    \"\"\"\n",
    "    optimized_model = GridSearchCV(model, hyperparameters, cv = folds, n_jobs = -1)\n",
    "    optimized_model.fit(X_train, y_train)\n",
    "    predicted = optimized_model.predict(X_test)\n",
    "    print 'Optimized parameters:', optimized_model.best_params_\n",
    "    print 'Model accuracy (hold-out):', optimized_model.score(X_test, y_test)\n",
    "    kfold_score = np.mean(cross_val_score(\n",
    "            optimized_model.best_estimator_, np.append(X_train, X_test, axis = 0), \n",
    "            np.append(y_train, y_test), cv = folds))\n",
    "    print 'Model accuracy ({0}-fold):'.format(str(folds)), kfold_score, '\\n'\n",
    "    return optimized_model\n",
    "\n",
    "\n",
    "def create_submission(name, model, train, outcomes, to_predict):\n",
    "    \"\"\"\n",
    "    Train [model] on [train] and predict the probabilties on [test], and\n",
    "    format the submission according to Kaggle.\n",
    "    \"\"\"\n",
    "    model.fit(np.array(train), outcomes)\n",
    "    probs = model.predict(np.array(to_predict))\n",
    "    results = pd.DataFrame(probs, columns = ['Survived'])\n",
    "    results['PassengerId'] = list(pd.read_csv('data/test.csv')['PassengerId'])\n",
    "    (results[['PassengerId', 'Survived']]\n",
    "        .to_csv('submissions/' + name, index = False))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model: random forest - scores ~ .799 on the public leaderboard, ~ 0.841 in local 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'n_estimators': 800}\n",
      "Model accuracy (hold-out): 0.793296089385\n",
      "Model accuracy (5-fold): 0.822658094388 \n",
      "\n",
      "CPU times: user 16 s, sys: 188 ms, total: 16.2 s\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = train_test_model(\n",
    "    RandomForestClassifier(), {'n_estimators': [500, 800, 1000]}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model: logistic regression - scores ~ .799 on the public leaderboard, 0.845 in local 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'C': 100}\n",
      "Model accuracy (hold-out): 0.810055865922\n",
      "Model accuracy (5-fold): 0.831596358165 \n",
      "\n",
      "CPU times: user 396 ms, sys: 60 ms, total: 456 ms\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model = train_test_model(\n",
    "    LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third model: SVM w/ Gaussian kernal - scores ~ .770 on the public leaderboard, ~ .802 in local 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'C': 100}\n",
      "Model accuracy (hold-out): 0.804469273743\n",
      "Model accuracy (5-fold): 0.784505638192 \n",
      "\n",
      "CPU times: user 3.2 s, sys: 84 ms, total: 3.29 s\n",
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_model = train_test_model(\n",
    "    SVC(), {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth model: Gradient Boosted Trees - scores ~.794 on the public leaderboard, .828 in local 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.139045+0.00652761\ttest-error:0.192135+0.0223028\n",
      "[1]\ttrain-error:0.13455+0.00630604\ttest-error:0.18764+0.0153239\n",
      "[2]\ttrain-error:0.130337+0.00337075\ttest-error:0.177528+0.0135765\n",
      "[3]\ttrain-error:0.126124+0.00257405\ttest-error:0.168539+0.0158901\n",
      "[4]\ttrain-error:0.127528+0.00578402\ttest-error:0.168539+0.0123084\n",
      "[5]\ttrain-error:0.124719+0.0027232\ttest-error:0.170786+0.0126124\n",
      "[6]\ttrain-error:0.124719+0.00520978\ttest-error:0.173033+0.0108937\n",
      "[7]\ttrain-error:0.126404+0.00502484\ttest-error:0.174157+0.00794505\n",
      "[8]\ttrain-error:0.124719+0.00473379\ttest-error:0.173033+0.0114585\n",
      "[9]\ttrain-error:0.12191+0.00513351\ttest-error:0.170786+0.0149062\n",
      "[10]\ttrain-error:0.124158+0.0036191\ttest-error:0.170786+0.0153239\n",
      "[11]\ttrain-error:0.122753+0.00302507\ttest-error:0.170786+0.0144766\n",
      "[12]\ttrain-error:0.120506+0.00550445\ttest-error:0.161797+0.0195906\n",
      "[13]\ttrain-error:0.119663+0.00473372\ttest-error:0.166292+0.019655\n",
      "[14]\ttrain-error:0.119663+0.00286477\ttest-error:0.166292+0.019655\n",
      "[15]\ttrain-error:0.120225+0.00522478\ttest-error:0.168539+0.0154878\n",
      "[16]\ttrain-error:0.11854+0.00383099\ttest-error:0.170786+0.0190018\n",
      "[17]\ttrain-error:0.119944+0.00522502\ttest-error:0.169663+0.0160482\n",
      "[18]\ttrain-error:0.117978+0.00809262\ttest-error:0.167415+0.0182563\n",
      "[19]\ttrain-error:0.117978+0.00682291\ttest-error:0.167415+0.0182563\n",
      "[20]\ttrain-error:0.117697+0.0063684\ttest-error:0.170786+0.0202871\n",
      "[21]\ttrain-error:0.117416+0.00631849\ttest-error:0.170786+0.0179776\n",
      "[22]\ttrain-error:0.117135+0.0071943\ttest-error:0.164045+0.0205345\n",
      "[23]\ttrain-error:0.116011+0.00593222\ttest-error:0.168539+0.0137612\n",
      "[24]\ttrain-error:0.117978+0.0046156\ttest-error:0.165168+0.0161267\n",
      "[25]\ttrain-error:0.11573+0.00499332\ttest-error:0.167415+0.0189352\n",
      "[26]\ttrain-error:0.116573+0.00502484\ttest-error:0.167415+0.0168165\n",
      "[27]\ttrain-error:0.116573+0.00670648\ttest-error:0.166292+0.0144766\n",
      "[28]\ttrain-error:0.11545+0.00571556\ttest-error:0.167415+0.0160482\n",
      "[29]\ttrain-error:0.11545+0.00661155\ttest-error:0.168539+0.0158901\n",
      "[30]\ttrain-error:0.115169+0.00510269\ttest-error:0.166292+0.0131033\n",
      "[31]\ttrain-error:0.116011+0.00619271\ttest-error:0.166292+0.0161267\n",
      "[32]\ttrain-error:0.11545+0.0053591\ttest-error:0.164045+0.0156499\n",
      "[33]\ttrain-error:0.115731+0.00679972\ttest-error:0.161797+0.0148213\n",
      "[34]\ttrain-error:0.116011+0.00537401\ttest-error:0.162921+0.0137612\n",
      "[35]\ttrain-error:0.117135+0.00491372\ttest-error:0.164045+0.0139435\n",
      "[36]\ttrain-error:0.116012+0.00431519\ttest-error:0.167415+0.0119968\n",
      "[37]\ttrain-error:0.116573+0.00478355\ttest-error:0.165168+0.0131033\n",
      "[38]\ttrain-error:0.116011+0.00422275\ttest-error:0.166292+0.0121015\n",
      "[39]\ttrain-error:0.116854+0.00429676\ttest-error:0.164045+0.0119968\n",
      "[40]\ttrain-error:0.115731+0.00315322\ttest-error:0.162921+0.0123084\n",
      "[41]\ttrain-error:0.115169+0.00344039\ttest-error:0.165168+0.0115682\n",
      "[42]\ttrain-error:0.113764+0.00435162\ttest-error:0.165168+0.0144766\n",
      "[43]\ttrain-error:0.114326+0.00383094\ttest-error:0.167415+0.0130066\n",
      "[44]\ttrain-error:0.112921+0.00372639\ttest-error:0.167415+0.0164369\n",
      "[45]\ttrain-error:0.11236+0.00426013\ttest-error:0.169663+0.0179072\n",
      "[46]\ttrain-error:0.113483+0.0044768\ttest-error:0.167415+0.0148213\n",
      "[47]\ttrain-error:0.112922+0.0044944\ttest-error:0.165168+0.0172611\n",
      "[48]\ttrain-error:0.112641+0.0048163\ttest-error:0.165168+0.0144766\n",
      "[49]\ttrain-error:0.112641+0.0048163\ttest-error:0.162921+0.0154878\n",
      "[50]\ttrain-error:0.11236+0.00387172\ttest-error:0.160674+0.017623\n",
      "[51]\ttrain-error:0.113202+0.00361925\ttest-error:0.165168+0.0144766\n",
      "[52]\ttrain-error:0.113203+0.00412849\ttest-error:0.167415+0.0139435\n",
      "[53]\ttrain-error:0.113203+0.0037267\ttest-error:0.165168+0.0144766\n",
      "[54]\ttrain-error:0.112922+0.00383099\ttest-error:0.164045+0.0156499\n",
      "[55]\ttrain-error:0.113202+0.00522506\ttest-error:0.164045+0.0143891\n",
      "[56]\ttrain-error:0.113483+0.00464953\ttest-error:0.164045+0.0143891\n",
      "[57]\ttrain-error:0.111798+0.00507181\ttest-error:0.161797+0.0148213\n",
      "[58]\ttrain-error:0.111236+0.00447682\ttest-error:0.161797+0.0139435\n",
      "[59]\ttrain-error:0.110955+0.0047003\ttest-error:0.160674+0.0161267\n",
      "[60]\ttrain-error:0.110394+0.00483289\ttest-error:0.165168+0.0135765\n",
      "[61]\ttrain-error:0.109551+0.00470042\ttest-error:0.161797+0.0130066\n",
      "[62]\ttrain-error:0.10927+0.00456408\ttest-error:0.161797+0.0156499\n",
      "[63]\ttrain-error:0.108427+0.00520992\ttest-error:0.162921+0.0174067\n",
      "[64]\ttrain-error:0.10927+0.00489762\ttest-error:0.162921+0.0170402\n",
      "[65]\ttrain-error:0.107865+0.00528514\ttest-error:0.165168+0.0161267\n",
      "[66]\ttrain-error:0.108146+0.00425999\ttest-error:0.164045+0.0143891\n",
      "[67]\ttrain-error:0.107585+0.00449439\ttest-error:0.164045+0.0130066\n",
      "[68]\ttrain-error:0.107585+0.00483266\ttest-error:0.165168+0.0190018\n",
      "[69]\ttrain-error:0.107304+0.00565985\ttest-error:0.165168+0.0190018\n",
      "[70]\ttrain-error:0.107304+0.00491388\ttest-error:0.167415+0.0164369\n",
      "[71]\ttrain-error:0.107585+0.00499355\ttest-error:0.167415+0.0179072\n",
      "[72]\ttrain-error:0.106742+0.00494558\ttest-error:0.166292+0.0179776\n",
      "[73]\ttrain-error:0.106742+0.00502489\ttest-error:0.169663+0.0164369\n",
      "[74]\ttrain-error:0.107303+0.00449451\ttest-error:0.169663+0.0164369\n",
      "[75]\ttrain-error:0.107304+0.00475053\ttest-error:0.169663+0.0164369\n",
      "[76]\ttrain-error:0.107304+0.00491388\ttest-error:0.168539+0.01465\n",
      "[77]\ttrain-error:0.106742+0.00510269\ttest-error:0.169663+0.0164369\n",
      "[78]\ttrain-error:0.106461+0.00543246\ttest-error:0.170786+0.0168914\n",
      "[79]\ttrain-error:0.10618+0.0055899\ttest-error:0.168539+0.01465\n",
      "[80]\ttrain-error:0.10618+0.0050717\ttest-error:0.167415+0.0148213\n",
      "[81]\ttrain-error:0.105337+0.00502495\ttest-error:0.166292+0.0144766\n",
      "[82]\ttrain-error:0.104775+0.0053739\ttest-error:0.169663+0.0143891\n",
      "[83]\ttrain-error:0.104775+0.00551883\ttest-error:0.167415+0.0160482\n",
      "[84]\ttrain-error:0.105337+0.0047003\ttest-error:0.166292+0.0161267\n",
      "[85]\ttrain-error:0.104775+0.00522517\ttest-error:0.166292+0.0161267\n",
      "[86]\ttrain-error:0.103933+0.00426026\ttest-error:0.167415+0.0192657\n",
      "[87]\ttrain-error:0.10309+0.00403185\ttest-error:0.168539+0.0200996\n",
      "[88]\ttrain-error:0.101686+0.00422301\ttest-error:0.166292+0.0179776\n",
      "[89]\ttrain-error:0.101966+0.00383099\ttest-error:0.167415+0.0179072\n",
      "[90]\ttrain-error:0.101686+0.0036191\ttest-error:0.169663+0.0185989\n",
      "[91]\ttrain-error:0.101966+0.0036191\ttest-error:0.170786+0.0193311\n",
      "[92]\ttrain-error:0.101405+0.00370531\ttest-error:0.169663+0.0185989\n",
      "[93]\ttrain-error:0.101685+0.00431545\ttest-error:0.170786+0.0168914\n",
      "[94]\ttrain-error:0.100281+0.00403158\ttest-error:0.169663+0.0185989\n",
      "[95]\ttrain-error:0.101124+0.00444155\ttest-error:0.169663+0.0185989\n",
      "[96]\ttrain-error:0.101124+0.00444155\ttest-error:0.169663+0.0164369\n",
      "[97]\ttrain-error:0.101405+0.00481665\ttest-error:0.170786+0.0149062\n",
      "[98]\ttrain-error:0.101124+0.00494593\ttest-error:0.170786+0.0149062\n",
      "[99]\ttrain-error:0.100843+0.00481656\ttest-error:0.170786+0.0149062\n"
     ]
    }
   ],
   "source": [
    "xbg_param = {\n",
    "    'learning_rate' : 0.025,\n",
    "    'n_estimators' : 1000,\n",
    "    'max_depth' : 5,\n",
    "    'gamma' : 0,\n",
    "    'subsample' : 0.8,\n",
    "    'colsample_bytree' : 0.8,\n",
    "    'objective' : 'binary:logistic',\n",
    "    'nthread' : 4,\n",
    "    'seed' : 27\n",
    "}\n",
    "\n",
    "xgb1 = xgb.XGBClassifier( **xbg_param )\n",
    "\n",
    "xgtrain = xgb.DMatrix(np.array(train), label = np.array(outcomes))\n",
    "cvresult = xgb.cv(xbg_param, xgtrain, num_boost_round = xgb1.get_params()['n_estimators'],\n",
    "                 nfold = 5, metrics = 'error', early_stopping_rounds = 50, verbose_eval = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'reg_alpha': 1e-05, 'max_depth': 3, 'gamma': 0.1, 'min_child_weight': 5}\n",
      "Model accuracy (hold-out): 0.826815642458\n",
      "Model accuracy (5-fold): 0.82828876791 \n",
      "\n",
      "CPU times: user 34 s, sys: 648 ms, total: 34.7 s\n",
      "Wall time: 36min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm_model = train_test_model(\n",
    "    xgb.XGBClassifier(learning_rate = 0.025, n_estimators = 99), \n",
    "    {'max_depth':range(3, 10, 2), 'min_child_weight':range(1, 6, 2),\n",
    "    'gamma': [i / 10.0 for i in range(0, 5)], 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]}, \n",
    "    np.array(X_train), np.array(X_test), y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815642458101\n",
      "CPU times: user 6.43 s, sys: 0 ns, total: 6.43 s\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm_model = xgb.XGBClassifier(learning_rate = 0.025, n_estimators = 500)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "gbm_model.predict(X_test)\n",
    "print gbm_model.score(X_test, y_test)\n",
    "\n",
    "gbm_model = xgb.XGBClassifier(learning_rate = 0.025, n_estimators = 500).fit(train, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03846174,  0.96153826],\n",
       "       [ 0.69000459,  0.30999538],\n",
       "       [ 0.91415739,  0.08584262],\n",
       "       [ 0.43874055,  0.56125945],\n",
       "       [ 0.91110843,  0.08889156],\n",
       "       [ 0.54853308,  0.45146695],\n",
       "       [ 0.98482352,  0.01517646],\n",
       "       [ 0.95065665,  0.04934332],\n",
       "       [ 0.03389198,  0.96610802],\n",
       "       [ 0.28530294,  0.71469706],\n",
       "       [ 0.07155484,  0.92844516],\n",
       "       [ 0.09907222,  0.90092778],\n",
       "       [ 0.96811438,  0.03188561],\n",
       "       [ 0.24182338,  0.75817662],\n",
       "       [ 0.94996959,  0.0500304 ],\n",
       "       [ 0.83727479,  0.16272523],\n",
       "       [ 0.02925879,  0.97074121],\n",
       "       [ 0.08812642,  0.91187358],\n",
       "       [ 0.57545519,  0.42454481],\n",
       "       [ 0.22533637,  0.77466363],\n",
       "       [ 0.71841681,  0.28158322],\n",
       "       [ 0.32005388,  0.67994612],\n",
       "       [ 0.07019538,  0.92980462],\n",
       "       [ 0.06015736,  0.93984264],\n",
       "       [ 0.27753407,  0.72246593],\n",
       "       [ 0.94475341,  0.05524658],\n",
       "       [ 0.92414546,  0.07585452],\n",
       "       [ 0.11311734,  0.88688266],\n",
       "       [ 0.04283178,  0.95716822],\n",
       "       [ 0.92131448,  0.07868551],\n",
       "       [ 0.58190691,  0.41809309],\n",
       "       [ 0.91467226,  0.08532771],\n",
       "       [ 0.97846556,  0.02153441],\n",
       "       [ 0.52609158,  0.47390845],\n",
       "       [ 0.09948671,  0.90051329],\n",
       "       [ 0.03389198,  0.96610802],\n",
       "       [ 0.10082209,  0.89917791],\n",
       "       [ 0.84683788,  0.15316209],\n",
       "       [ 0.16572702,  0.83427298],\n",
       "       [ 0.99442655,  0.00557344],\n",
       "       [ 0.05641645,  0.94358355],\n",
       "       [ 0.04877776,  0.95122224],\n",
       "       [ 0.18555111,  0.81444889],\n",
       "       [ 0.6808188 ,  0.31918117],\n",
       "       [ 0.87289315,  0.12710686],\n",
       "       [ 0.95282584,  0.04717417],\n",
       "       [ 0.91247827,  0.08752175],\n",
       "       [ 0.49476784,  0.50523216],\n",
       "       [ 0.64852786,  0.35147217],\n",
       "       [ 0.94859117,  0.05140884],\n",
       "       [ 0.1510424 ,  0.8489576 ],\n",
       "       [ 0.03947121,  0.96052879],\n",
       "       [ 0.9467833 ,  0.05321671],\n",
       "       [ 0.9801091 ,  0.0198909 ],\n",
       "       [ 0.95701694,  0.04298307],\n",
       "       [ 0.76352412,  0.2364759 ],\n",
       "       [ 0.93926156,  0.06073845],\n",
       "       [ 0.94035786,  0.05964213],\n",
       "       [ 0.90627599,  0.093724  ],\n",
       "       [ 0.93894213,  0.06105785],\n",
       "       [ 0.91076505,  0.08923496],\n",
       "       [ 0.95774502,  0.04225499],\n",
       "       [ 0.62827981,  0.37172019],\n",
       "       [ 0.93295819,  0.06704182],\n",
       "       [ 0.84618425,  0.15381575],\n",
       "       [ 0.9196974 ,  0.08030262],\n",
       "       [ 0.92039156,  0.07960841],\n",
       "       [ 0.71141845,  0.28858155],\n",
       "       [ 0.06156665,  0.93843335],\n",
       "       [ 0.94446111,  0.05553891],\n",
       "       [ 0.14936948,  0.85063052],\n",
       "       [ 0.0236662 ,  0.9763338 ],\n",
       "       [ 0.82915491,  0.17084509],\n",
       "       [ 0.69053638,  0.30946365],\n",
       "       [ 0.7606402 ,  0.2393598 ],\n",
       "       [ 0.10677576,  0.89322424],\n",
       "       [ 0.87122774,  0.12877229],\n",
       "       [ 0.88439965,  0.11560032],\n",
       "       [ 0.87549382,  0.12450617],\n",
       "       [ 0.93646288,  0.06353715],\n",
       "       [ 0.92901719,  0.07098279],\n",
       "       [ 0.47781533,  0.52218467],\n",
       "       [ 0.08647299,  0.91352701],\n",
       "       [ 0.8544367 ,  0.1455633 ],\n",
       "       [ 0.03860199,  0.96139801],\n",
       "       [ 0.88695627,  0.1130437 ],\n",
       "       [ 0.66684127,  0.33315873],\n",
       "       [ 0.16035914,  0.83964086],\n",
       "       [ 0.94608641,  0.05391359],\n",
       "       [ 0.13800108,  0.86199892],\n",
       "       [ 0.96098727,  0.0390127 ],\n",
       "       [ 0.33632696,  0.66367304],\n",
       "       [ 0.18781137,  0.81218863],\n",
       "       [ 0.91742235,  0.08257762],\n",
       "       [ 0.25614786,  0.74385214],\n",
       "       [ 0.0236662 ,  0.9763338 ],\n",
       "       [ 0.80743814,  0.19256186],\n",
       "       [ 0.87503225,  0.12496773],\n",
       "       [ 0.04334688,  0.95665312],\n",
       "       [ 0.89417917,  0.10582084],\n",
       "       [ 0.57735586,  0.42264411],\n",
       "       [ 0.16010302,  0.83989698],\n",
       "       [ 0.31589359,  0.68410641],\n",
       "       [ 0.80559528,  0.19440471],\n",
       "       [ 0.5837062 ,  0.4162938 ],\n",
       "       [ 0.93978339,  0.06021663],\n",
       "       [ 0.027686  ,  0.972314  ],\n",
       "       [ 0.92529166,  0.07470831],\n",
       "       [ 0.93907058,  0.06092944],\n",
       "       [ 0.92167312,  0.0783269 ],\n",
       "       [ 0.04999143,  0.95000857],\n",
       "       [ 0.53840566,  0.46159437],\n",
       "       [ 0.54745972,  0.45254028],\n",
       "       [ 0.88191986,  0.11808015],\n",
       "       [ 0.97939277,  0.02060724],\n",
       "       [ 0.9677    ,  0.0323    ],\n",
       "       [ 0.32514751,  0.67485249],\n",
       "       [ 0.05280393,  0.94719607],\n",
       "       [ 0.44666493,  0.55333507],\n",
       "       [ 0.94494444,  0.05505554],\n",
       "       [ 0.88671583,  0.11328415],\n",
       "       [ 0.88056576,  0.11943421],\n",
       "       [ 0.94446713,  0.05553288],\n",
       "       [ 0.92083555,  0.07916443],\n",
       "       [ 0.04335421,  0.95664579],\n",
       "       [ 0.89610463,  0.10389534],\n",
       "       [ 0.885414  ,  0.11458603],\n",
       "       [ 0.95056242,  0.0494376 ],\n",
       "       [ 0.9279564 ,  0.07204359],\n",
       "       [ 0.94369942,  0.05630058],\n",
       "       [ 0.64688671,  0.35311332],\n",
       "       [ 0.03203166,  0.96796834],\n",
       "       [ 0.92495781,  0.0750422 ],\n",
       "       [ 0.50014091,  0.49985912],\n",
       "       [ 0.89239019,  0.10760979],\n",
       "       [ 0.03025132,  0.96974868],\n",
       "       [ 0.26731503,  0.73268497],\n",
       "       [ 0.55989385,  0.44010615],\n",
       "       [ 0.95072889,  0.04927108],\n",
       "       [ 0.9428302 ,  0.05716981],\n",
       "       [ 0.97951001,  0.02049001],\n",
       "       [ 0.04527503,  0.95472497],\n",
       "       [ 0.10197103,  0.89802897],\n",
       "       [ 0.7221179 ,  0.27788207],\n",
       "       [ 0.92989945,  0.07010054],\n",
       "       [ 0.67441201,  0.32558796],\n",
       "       [ 0.17952335,  0.82047665],\n",
       "       [ 0.95393085,  0.04606917],\n",
       "       [ 0.70902157,  0.2909784 ],\n",
       "       [ 0.86021042,  0.13978957],\n",
       "       [ 0.77488965,  0.22511037],\n",
       "       [ 0.63010931,  0.36989066],\n",
       "       [ 0.92314905,  0.07685095],\n",
       "       [ 0.64235395,  0.35764605],\n",
       "       [ 0.31028587,  0.68971413],\n",
       "       [ 0.92226541,  0.07773457],\n",
       "       [ 0.07331133,  0.92668867],\n",
       "       [ 0.9803701 ,  0.01962988],\n",
       "       [ 0.02841562,  0.97158438],\n",
       "       [ 0.08901387,  0.91098613],\n",
       "       [ 0.88871455,  0.11128543],\n",
       "       [ 0.94537824,  0.05462174],\n",
       "       [ 0.93385381,  0.06614619],\n",
       "       [ 0.72924459,  0.27075538],\n",
       "       [ 0.45067537,  0.54932463],\n",
       "       [ 0.97469974,  0.02530027],\n",
       "       [ 0.83171052,  0.16828947],\n",
       "       [ 0.87094337,  0.12905662],\n",
       "       [ 0.48703152,  0.51296848],\n",
       "       [ 0.06049794,  0.93950206],\n",
       "       [ 0.1303246 ,  0.8696754 ],\n",
       "       [ 0.85948569,  0.14051433],\n",
       "       [ 0.89608991,  0.10391009],\n",
       "       [ 0.60542285,  0.39457718],\n",
       "       [ 0.93919921,  0.06080076],\n",
       "       [ 0.89953613,  0.10046384],\n",
       "       [ 0.24672723,  0.75327277],\n",
       "       [ 0.968759  ,  0.03124101],\n",
       "       [ 0.28704739,  0.71295261]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model.predict_proba(np.array(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamSize</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_Abbott_3</th>\n",
       "      <th>Family_Allison_4</th>\n",
       "      <th>Family_Andersson_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_A</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100131</td>\n",
       "      <td>0.840978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex   Age     Fare  FamSize  Pclass_1  Pclass_2  Pclass_3  Family_Abbott_3  \\\n",
       "0  1.0  22.0   7.2500      2.0       0.0       0.0       1.0              0.0   \n",
       "1  0.0  38.0  71.2833      2.0       1.0       0.0       0.0              0.0   \n",
       "2  0.0  26.0   7.9250      1.0       0.0       0.0       1.0              0.0   \n",
       "3  0.0  35.0  53.1000      2.0       1.0       0.0       0.0              0.0   \n",
       "4  1.0  35.0   8.0500      1.0       0.0       0.0       1.0              0.0   \n",
       "\n",
       "   Family_Allison_4  Family_Andersson_7     ...      Deck_A    Deck_B  Deck_C  \\\n",
       "0               0.0                 0.0     ...         0.0  0.000000     0.0   \n",
       "1               0.0                 0.0     ...         0.0  0.000000     1.0   \n",
       "2               0.0                 0.0     ...         0.0  0.000000     0.0   \n",
       "3               0.0                 0.0     ...         0.0  0.000000     1.0   \n",
       "4               0.0                 0.0     ...         0.0  0.058891     0.0   \n",
       "\n",
       "   Deck_D    Deck_E    Deck_F  Deck_G  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0     0.0  0.000000  1.000000     0.0         0.0         0.0         1.0  \n",
       "1     0.0  0.000000  0.000000     0.0         1.0         0.0         0.0  \n",
       "2     0.0  0.000000  1.000000     0.0         0.0         0.0         1.0  \n",
       "3     0.0  0.000000  0.000000     0.0         0.0         0.0         1.0  \n",
       "4     0.0  0.100131  0.840978     0.0         0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 335 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission('lr2_model.csv', lr_model, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission('rf2_model.csv', rf_model, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission('svm_model.csv', svm_model, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission('gbm2_model.csv', gbm_model, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating a majority voting ensemble from the exported models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = pd.read_csv('submissions/lr2_model.csv')\n",
    "rf = pd.read_csv('submissions/rf_model.csv')\n",
    "svm = pd.read_csv('submissions/svm_model.csv')\n",
    "gbm = pd.read_csv('submissions/gbm_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble = rf.copy()[['PassengerId']]\n",
    "ensemble['Survived'] = 0\n",
    "\n",
    "def add_to_ensemble(data, ensemble):\n",
    "    data = data.copy()\n",
    "    data['Survived'] = np.where(data['Survived'] == 0, -1, 1)\n",
    "    ensemble['Survived'] = ensemble['Survived'] + data['Survived']\n",
    "    return ensemble\n",
    "\n",
    "# The random forest model gets 2 votes\n",
    "ensemble = add_to_ensemble(lr, ensemble)\n",
    "ensemble = add_to_ensemble(lr, ensemble)\n",
    "ensemble = add_to_ensemble(lr, ensemble)\n",
    "ensemble = add_to_ensemble(rf, ensemble)\n",
    "ensemble = add_to_ensemble(gbm, ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble['Survived'] = np.where(ensemble['Survived'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble.to_csv('submissions/ensemble_majority2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
