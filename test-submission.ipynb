{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Kaggle - Data Processing and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import fancyimpute\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ingest_data():\n",
    "    train = pd.read_csv('data/train.csv').assign(Train = 1)\n",
    "    test = (pd.read_csv('data/test.csv').assign(Train = 0)\n",
    "            .assign(Survived = -999)[list(train)])\n",
    "    return pd.concat([train, test])\n",
    "\n",
    "\n",
    "extract_lastname = lambda x: x.split(',')[0]\n",
    "\n",
    "\n",
    "def extract_title(x):\n",
    "    \"\"\"Get the person's title from their name. Combine reduntant or less common \n",
    "    titles together.\n",
    "    \"\"\"\n",
    "    title = x.split(',')[1].split('.')[0][1:]\n",
    "    if title in ['Mlle', 'Ms']:\n",
    "        title = 'Miss'\n",
    "    elif title == 'Mme':\n",
    "        title = 'Mrs'\n",
    "    elif title in ['Rev', 'Dr', 'Major', 'Col', 'Capt', 'Jonkheer', 'Dona']:\n",
    "        title = 'Esteemed'\n",
    "    elif title in ['Don', 'Lady', 'Sir', 'the Countess']:\n",
    "        title = 'Royalty'\n",
    "    return title\n",
    "\n",
    "\n",
    "first_letter = np.vectorize(lambda x: x[:1]) \n",
    "\n",
    "\n",
    "def ticket_counts(data):\n",
    "    \"\"\"Tickets in cases where 2 or more people shared a single ticket.\n",
    "    \"\"\"\n",
    "    ticket_to_count = dict(data.Ticket.value_counts())\n",
    "    data['TicketCount'] = data['Ticket'].map(ticket_to_count.get)\n",
    "    data['Ticket'] = np.where(data['TicketCount'] > 1, data['Ticket'], np.nan)\n",
    "    return data.drop(['TicketCount'], axis = 1)\n",
    "\n",
    "\n",
    "def create_dummy_nans(data, col_name):\n",
    "    \"\"\"Create dummies for a column in a DataFrame, and preserve np.nans in their \n",
    "    original places instead of in a separate _nan column.\n",
    "    \"\"\"\n",
    "    deck_cols = [col for col in list(data) if col_name in col]\n",
    "    for deck_col in deck_cols:\n",
    "        data[deck_col] = np.where(\n",
    "            data[col_name + 'nan'] == 1.0, np.nan, data[deck_col])\n",
    "    return data.drop([col_name + 'nan'], axis = 1)\n",
    "\n",
    "\n",
    "def impute(data):\n",
    "    \"\"\"Impute missing values in the Age, Deck, Embarked, and Fare features.\n",
    "    \"\"\"\n",
    "    impute_missing = data.drop(['Survived', 'Train'], axis = 1)\n",
    "    impute_missing_cols = list(impute_missing)\n",
    "    filled_soft = fancyimpute.MICE().complete(np.array(impute_missing))\n",
    "    results = pd.DataFrame(filled_soft, columns = impute_missing_cols)\n",
    "    results['Train'] = list(data['Train'])\n",
    "    results['Survived'] = list(data['Survived'])\n",
    "    assert results.isnull().sum().sum() == 0, 'Not all NAs removed'\n",
    "    return results\n",
    "\n",
    "\n",
    "def feature_engineering(data):\n",
    "    return (data\n",
    "\n",
    "        # Create last name, title, family size, and family features\n",
    "        .assign(LastName = lambda x: x.Name.map(extract_lastname))\n",
    "        .assign(Title = lambda x: x.Name.map(extract_title))\n",
    "        .assign(FamSize = lambda x: x.SibSp + x.Parch + 1)\n",
    "        .assign(Family = lambda x: [a + '_' + str(b) for a, b in zip(\n",
    "                    list(x.LastName), list(x.FamSize))])\n",
    "            \n",
    "        # Create ticket counts for passengers sharing tickets\n",
    "        .pipe(ticket_counts)\n",
    "\n",
    "        # Turn the Cabin feature into a Deck feature (A-G)\n",
    "        .assign(Deck = lambda x: np.where(\n",
    "            pd.notnull(x.Cabin), first_letter(x.Cabin.fillna('z')), x.Cabin))\n",
    "        .assign(Deck = lambda x: np.where(x.Deck == 'T', np.nan, x.Deck))\n",
    "\n",
    "        # Turn Sex into a dummy variable\n",
    "        .assign(Sex = lambda x: np.where(x.Sex == 'male', 1, 0))\n",
    "\n",
    "        # Create dummy variables for the categorical features\n",
    "        .assign(Pclass = lambda x: x.Pclass.astype(str))\n",
    "        .pipe(pd.get_dummies, columns = ['Pclass', 'Family', 'Title', 'Ticket'])\n",
    "        .pipe(pd.get_dummies, columns = ['Deck'], dummy_na = True)\n",
    "        .pipe(pd.get_dummies, columns = ['Embarked'], dummy_na = True)\n",
    "        .pipe(create_dummy_nans, 'Deck_')\n",
    "        .pipe(create_dummy_nans, 'Embarked_')\n",
    "\n",
    "        # Drop columns we don't need\n",
    "        .drop(['Name', 'Cabin', 'PassengerId', 'SibSp', 'Parch', 'LastName'], axis = 1)\n",
    "\n",
    "        # Impute NAs using MICE\n",
    "        .pipe(impute)\n",
    "    )\n",
    "\n",
    "\n",
    "def split_data(data):\n",
    "    \"\"\"\n",
    "    Split the combined training/prediction data into separate training and \n",
    "    prediction sets.\n",
    "    \"\"\"\n",
    "    outcomes = np.array(data.query('Train == 1')['Survived'])\n",
    "    train = (data.query('Train == 1')\n",
    "             .drop(['Train', 'Survived'], axis = 1))\n",
    "    to_predict = (data.query('Train == 0')\n",
    "                  .drop(['Train', 'Survived'], axis = 1))\n",
    "    return train, outcomes, to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MICE] Completing matrix with shape (1309, 1167)\n",
      "[MICE] Starting imputation round 1/110, elapsed time 0.019\n",
      "[MICE] Starting imputation round 2/110, elapsed time 2.703\n",
      "[MICE] Starting imputation round 3/110, elapsed time 4.815\n",
      "[MICE] Starting imputation round 4/110, elapsed time 6.975\n",
      "[MICE] Starting imputation round 5/110, elapsed time 9.106\n",
      "[MICE] Starting imputation round 6/110, elapsed time 11.229\n",
      "[MICE] Starting imputation round 7/110, elapsed time 13.350\n",
      "[MICE] Starting imputation round 8/110, elapsed time 15.471\n",
      "[MICE] Starting imputation round 9/110, elapsed time 17.555\n",
      "[MICE] Starting imputation round 10/110, elapsed time 19.637\n",
      "[MICE] Starting imputation round 11/110, elapsed time 21.720\n",
      "[MICE] Starting imputation round 12/110, elapsed time 23.809\n",
      "[MICE] Starting imputation round 13/110, elapsed time 25.896\n",
      "[MICE] Starting imputation round 14/110, elapsed time 27.984\n",
      "[MICE] Starting imputation round 15/110, elapsed time 30.075\n",
      "[MICE] Starting imputation round 16/110, elapsed time 32.166\n",
      "[MICE] Starting imputation round 17/110, elapsed time 34.253\n",
      "[MICE] Starting imputation round 18/110, elapsed time 36.343\n",
      "[MICE] Starting imputation round 19/110, elapsed time 38.427\n",
      "[MICE] Starting imputation round 20/110, elapsed time 40.507\n",
      "[MICE] Starting imputation round 21/110, elapsed time 42.585\n",
      "[MICE] Starting imputation round 22/110, elapsed time 44.665\n",
      "[MICE] Starting imputation round 23/110, elapsed time 46.744\n",
      "[MICE] Starting imputation round 24/110, elapsed time 48.825\n",
      "[MICE] Starting imputation round 25/110, elapsed time 50.904\n",
      "[MICE] Starting imputation round 26/110, elapsed time 52.988\n",
      "[MICE] Starting imputation round 27/110, elapsed time 55.071\n",
      "[MICE] Starting imputation round 28/110, elapsed time 57.154\n",
      "[MICE] Starting imputation round 29/110, elapsed time 59.255\n",
      "[MICE] Starting imputation round 30/110, elapsed time 61.358\n",
      "[MICE] Starting imputation round 31/110, elapsed time 63.488\n",
      "[MICE] Starting imputation round 32/110, elapsed time 65.608\n",
      "[MICE] Starting imputation round 33/110, elapsed time 67.727\n",
      "[MICE] Starting imputation round 34/110, elapsed time 69.852\n",
      "[MICE] Starting imputation round 35/110, elapsed time 71.974\n",
      "[MICE] Starting imputation round 36/110, elapsed time 74.100\n",
      "[MICE] Starting imputation round 37/110, elapsed time 76.222\n",
      "[MICE] Starting imputation round 38/110, elapsed time 78.358\n",
      "[MICE] Starting imputation round 39/110, elapsed time 80.500\n",
      "[MICE] Starting imputation round 40/110, elapsed time 82.641\n",
      "[MICE] Starting imputation round 41/110, elapsed time 84.783\n",
      "[MICE] Starting imputation round 42/110, elapsed time 86.925\n",
      "[MICE] Starting imputation round 43/110, elapsed time 89.066\n",
      "[MICE] Starting imputation round 44/110, elapsed time 91.204\n",
      "[MICE] Starting imputation round 45/110, elapsed time 93.359\n",
      "[MICE] Starting imputation round 46/110, elapsed time 95.498\n",
      "[MICE] Starting imputation round 47/110, elapsed time 97.634\n",
      "[MICE] Starting imputation round 48/110, elapsed time 99.778\n",
      "[MICE] Starting imputation round 49/110, elapsed time 101.920\n",
      "[MICE] Starting imputation round 50/110, elapsed time 104.061\n",
      "[MICE] Starting imputation round 51/110, elapsed time 106.199\n",
      "[MICE] Starting imputation round 52/110, elapsed time 108.340\n",
      "[MICE] Starting imputation round 53/110, elapsed time 110.481\n",
      "[MICE] Starting imputation round 54/110, elapsed time 112.623\n",
      "[MICE] Starting imputation round 55/110, elapsed time 114.765\n",
      "[MICE] Starting imputation round 56/110, elapsed time 116.911\n",
      "[MICE] Starting imputation round 57/110, elapsed time 119.051\n",
      "[MICE] Starting imputation round 58/110, elapsed time 121.191\n",
      "[MICE] Starting imputation round 59/110, elapsed time 123.333\n",
      "[MICE] Starting imputation round 60/110, elapsed time 125.474\n",
      "[MICE] Starting imputation round 61/110, elapsed time 127.612\n",
      "[MICE] Starting imputation round 62/110, elapsed time 129.762\n",
      "[MICE] Starting imputation round 63/110, elapsed time 131.913\n",
      "[MICE] Starting imputation round 64/110, elapsed time 134.069\n",
      "[MICE] Starting imputation round 65/110, elapsed time 136.211\n",
      "[MICE] Starting imputation round 66/110, elapsed time 138.354\n",
      "[MICE] Starting imputation round 67/110, elapsed time 140.492\n",
      "[MICE] Starting imputation round 68/110, elapsed time 142.640\n",
      "[MICE] Starting imputation round 69/110, elapsed time 144.777\n",
      "[MICE] Starting imputation round 70/110, elapsed time 146.885\n",
      "[MICE] Starting imputation round 71/110, elapsed time 148.980\n",
      "[MICE] Starting imputation round 72/110, elapsed time 151.089\n",
      "[MICE] Starting imputation round 73/110, elapsed time 153.187\n",
      "[MICE] Starting imputation round 74/110, elapsed time 155.297\n",
      "[MICE] Starting imputation round 75/110, elapsed time 157.382\n",
      "[MICE] Starting imputation round 76/110, elapsed time 159.474\n",
      "[MICE] Starting imputation round 77/110, elapsed time 161.558\n",
      "[MICE] Starting imputation round 78/110, elapsed time 163.648\n",
      "[MICE] Starting imputation round 79/110, elapsed time 165.730\n",
      "[MICE] Starting imputation round 80/110, elapsed time 167.822\n",
      "[MICE] Starting imputation round 81/110, elapsed time 169.907\n",
      "[MICE] Starting imputation round 82/110, elapsed time 171.998\n",
      "[MICE] Starting imputation round 83/110, elapsed time 174.081\n",
      "[MICE] Starting imputation round 84/110, elapsed time 176.174\n",
      "[MICE] Starting imputation round 85/110, elapsed time 178.259\n",
      "[MICE] Starting imputation round 86/110, elapsed time 180.347\n",
      "[MICE] Starting imputation round 87/110, elapsed time 182.433\n",
      "[MICE] Starting imputation round 88/110, elapsed time 184.525\n",
      "[MICE] Starting imputation round 89/110, elapsed time 186.709\n",
      "[MICE] Starting imputation round 90/110, elapsed time 188.799\n",
      "[MICE] Starting imputation round 91/110, elapsed time 190.887\n",
      "[MICE] Starting imputation round 92/110, elapsed time 192.980\n",
      "[MICE] Starting imputation round 93/110, elapsed time 195.062\n",
      "[MICE] Starting imputation round 94/110, elapsed time 197.152\n",
      "[MICE] Starting imputation round 95/110, elapsed time 199.234\n",
      "[MICE] Starting imputation round 96/110, elapsed time 201.330\n",
      "[MICE] Starting imputation round 97/110, elapsed time 203.169\n",
      "[MICE] Starting imputation round 98/110, elapsed time 204.979\n",
      "[MICE] Starting imputation round 99/110, elapsed time 206.780\n",
      "[MICE] Starting imputation round 100/110, elapsed time 208.594\n",
      "[MICE] Starting imputation round 101/110, elapsed time 210.391\n",
      "[MICE] Starting imputation round 102/110, elapsed time 212.199\n",
      "[MICE] Starting imputation round 103/110, elapsed time 214.056\n",
      "[MICE] Starting imputation round 104/110, elapsed time 215.882\n",
      "[MICE] Starting imputation round 105/110, elapsed time 217.944\n",
      "[MICE] Starting imputation round 106/110, elapsed time 220.044\n",
      "[MICE] Starting imputation round 107/110, elapsed time 222.141\n",
      "[MICE] Starting imputation round 108/110, elapsed time 224.257\n",
      "[MICE] Starting imputation round 109/110, elapsed time 226.351\n",
      "[MICE] Starting imputation round 110/110, elapsed time 228.453\n"
     ]
    }
   ],
   "source": [
    "data = ingest_data()\n",
    "data = feature_engineering(data)\n",
    "train, outcomes, to_predict = split_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(model, hyperparameters, X_train, X_test, y_train, y_test,\n",
    "                    folds = 5):\n",
    "    \"\"\"\n",
    "    Given a [model] and a set of possible [hyperparameters], along with \n",
    "    matricies corresponding to hold-out cross-validation, returns a model w/ \n",
    "    optimized hyperparameters, and prints out model evaluation metrics.\n",
    "    \"\"\"\n",
    "    optimized_model = GridSearchCV(model, hyperparameters, cv = folds, n_jobs = -1)\n",
    "    optimized_model.fit(X_train, y_train)\n",
    "    predicted = optimized_model.predict(X_test)\n",
    "    print 'Optimized parameters:', optimized_model.best_params_\n",
    "    print 'Model accuracy (hold-out):', optimized_model.score(X_test, y_test)\n",
    "    kfold_score = np.mean(cross_val_score(\n",
    "            optimized_model.best_estimator_, np.append(X_train, X_test, axis = 0), \n",
    "            np.append(y_train, y_test), cv = folds, n_jobs = -1))\n",
    "    print 'Model accuracy ({0}-fold):'.format(str(folds)), kfold_score, '\\n'\n",
    "    return optimized_model\n",
    "\n",
    "\n",
    "def create_submission(name, model, train, outcomes, to_predict):\n",
    "    \"\"\"\n",
    "    Train [model] on [train] and predict the probabilties on [test], and\n",
    "    format the submission according to Kaggle.\n",
    "    \"\"\"\n",
    "    model.fit(np.array(train), outcomes)\n",
    "    probs = model.predict(np.array(to_predict))\n",
    "    results = pd.DataFrame(probs, columns = ['Survived'])\n",
    "    results['PassengerId'] = list(pd.read_csv('data/test.csv')['PassengerId'])\n",
    "    (results[['PassengerId', 'Survived']]\n",
    "        .to_csv('submissions/' + name, index = False))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train, outcomes, test_size = 0.2, random_state = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'min_samples_split': 3, 'max_depth': None, 'min_samples_leaf': 1}\n",
      "Model accuracy (hold-out): 0.798882681564\n",
      "Model accuracy (5-fold): 0.81925570974 \n",
      "\n",
      "CPU times: user 4.92 s, sys: 152 ms, total: 5.07 s\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = train_test_model(\n",
    "    RandomForestClassifier(n_estimators = 800, random_state = 25), {\n",
    "        'min_samples_split': [1, 3, 10],\n",
    "        'min_samples_leaf': [1, 3, 10],\n",
    "        'max_depth': [3, None]}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'n_neighbors': 19}\n",
      "Model accuracy (hold-out): 0.675977653631\n",
      "Model accuracy (5-fold): 0.687981858204 \n",
      "\n",
      "CPU times: user 768 ms, sys: 116 ms, total: 884 ms\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kNN_model = train_test_model(\n",
    "    KNeighborsClassifier(), {\n",
    "        'n_neighbors': np.array([num + 1 for num in range(0, 20) if num % 2 == 0])}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'C': 10, 'class_weight': 'balanced'}\n",
      "Model accuracy (hold-out): 0.837988826816\n",
      "Model accuracy (5-fold): 0.835017857732 \n",
      "\n",
      "CPU times: user 1.24 s, sys: 148 ms, total: 1.39 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_model = train_test_model(\n",
    "    LogisticRegression(random_state = 25), {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'class_weight': [None, 'balanced']}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'C': 1000, 'gamma': 0.0001}\n",
      "Model accuracy (hold-out): 0.826815642458\n",
      "Model accuracy (5-fold): 0.821534427955 \n",
      "\n",
      "CPU times: user 12.3 s, sys: 332 ms, total: 12.6 s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_model = train_test_model(\n",
    "    SVC(probability = True, random_state = 25), {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'gamma': np.logspace(-9, 3, 13)}, \n",
    "    X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized parameters: {'reg_alpha': 0.01, 'max_depth': 3, 'gamma': 0.1, 'min_child_weight': 1}\n",
      "Model accuracy (hold-out): 0.787709497207\n",
      "Model accuracy (5-fold): 0.822607665047 \n",
      "\n",
      "CPU times: user 42.3 s, sys: 1.38 s, total: 43.6 s\n",
      "Wall time: 1h 10min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbt_model = train_test_model(\n",
    "    xgb.XGBClassifier(learning_rate = 0.05, n_estimators = 200, seed = 25), {\n",
    "        'max_depth': range(3, 10, 2), \n",
    "        'min_child_weight': range(1, 6, 2),\n",
    "        'gamma': [i / 10.0 for i in range(0, 5)], \n",
    "        'reg_alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "    np.array(X_train), np.array(X_test), y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try submitting specific models before trying an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission('ensemble_rf.csv', rf_model.best_estimator_, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public leaderboard score of `0.81340`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission('ensemble_lr.csv', lr_model.best_estimator_, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public leaderboard score of `0.81340`, also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission('ensemble_svm.csv', svm_model.best_estimator_, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public leaderboard score of `0.77512`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission('ensemble_gbt.csv', gbt_model.best_estimator_, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public leaderboard score of `0.79904`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a majority vote ensemble - give one of the best models (RF or LR) two votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def majority_vote_ensemble(name, models_votes, train, outcomes, to_predict):\n",
    "    \"\"\"Creates a submission from a majority voting ensemble, given training/\n",
    "    testing data and a list of models and votes.\n",
    "    \"\"\"\n",
    "    model_results = []\n",
    "    for model, votes in models_votes:\n",
    "        model.fit(np.array(train), outcomes)\n",
    "        probs = model.predict(np.array(to_predict))\n",
    "        probs[probs == 0] = -1\n",
    "        model_results.append((probs, votes))\n",
    "    \n",
    "    # Assemble the ensemble\n",
    "    ensemble = pd.read_csv('data/test.csv')[['PassengerId']].assign(Survived = 0)\n",
    "    for probs, votes in model_results:\n",
    "        for i in range(0, votes):\n",
    "            ensemble = ensemble.assign(Survived = lambda x: x.Survived + probs)\n",
    "    (ensemble.assign(Survived = lambda x: np.where(x.Survived > 0, 1, 0))\n",
    "     .to_csv(name, index = False))\n",
    "    return None\n",
    "    \n",
    "    \n",
    "models_votes = [\n",
    "    (rf_model.best_estimator_, 2),\n",
    "    (lr_model.best_estimator_, 1),\n",
    "    (svm_model.best_estimator_, 1),\n",
    "    (gbt_model.best_estimator_, 1)\n",
    "]\n",
    "\n",
    "\n",
    "majority_vote_ensemble('submissions/ensemble_majority_vote.csv', \n",
    "                       models_votes, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public leaderboard score of `0.81340`, so not an improvement over the RF and LR models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a weighted average of probabilities ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_average_ensemble(name, models_weights, train, outcomes, to_predict):\n",
    "    \"\"\"Creates a submission from a weighted average of probabilities ensemble, \n",
    "    given training/testing data and a list of models and weights.\n",
    "    \"\"\"\n",
    "    weights_sum = sum([mw[1] for mw in models_weights])\n",
    "    model_results = []\n",
    "    for model, weight in models_votes:\n",
    "        model.fit(np.array(train), outcomes)\n",
    "        probs = model.predict_proba(np.array(to_predict))[:, 0]\n",
    "        model_results.append((probs, weight))\n",
    "    \n",
    "    # Assemble the ensemble\n",
    "    ensemble = pd.read_csv('data/test.csv')[['PassengerId']].assign(Survived = 0)\n",
    "    for probs, weight in model_results:\n",
    "        ensemble = ensemble.assign(Survived = lambda x: x.Survived + probs * weight)\n",
    "    (ensemble.assign(Survived = lambda x: x.Survived / weights_sum)\n",
    "     .assign(Survived = lambda x: np.where(x.Survived >= 0.5, 1, 0))\n",
    "     .to_csv(name, index = False))\n",
    "    return None\n",
    "\n",
    "\n",
    "# Simple average\n",
    "models_weights = [\n",
    "    (rf_model.best_estimator_, 1),\n",
    "    (lr_model.best_estimator_, 1),\n",
    "    (svm_model.best_estimator_, 1),\n",
    "    (gbt_model.best_estimator_, 1)\n",
    "]\n",
    "\n",
    "weighted_average_ensemble('submissions/ensemble_simpleavg.csv', \n",
    "                          models_weights, train, outcomes, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_sum = sum([mw[1] for mw in models_weights])\n",
    "model_results = []\n",
    "for model, weight in models_votes:\n",
    "    model.fit(np.array(train), outcomes)\n",
    "    probs = model.predict_proba(np.array(to_predict))[:, 0]\n",
    "    model_results.append((probs, weight))\n",
    "    \n",
    "ensemble = pd.read_csv('data/test.csv')[['PassengerId']].assign(Survived = 0)\n",
    "for probs, weight in model_results:\n",
    "    ensemble = ensemble.assign(Survived = lambda x: x.Survived + probs * weight)\n",
    "ensemble = (ensemble.assign(Survived = lambda x: x.Survived / weights_sum)\n",
    "            .assign(Predict = lambda x: np.where(x.Survived >= 0.5, 1, 0))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
